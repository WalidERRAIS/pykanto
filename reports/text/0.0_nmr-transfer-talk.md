## 1

Hi everyone, thanks for coming!

Today I’m gonna talk about the project I’ve working on this past year, which is about bird song. But first I should probably introduce myself and the research group I’m a part of.

## 2

Ok, so this is (currently) the Sheldon Lab. We study evolutionary and ecological processes that operate in wild populations, from things like how information flows through social networks to how individuals respond to environmental variation.

As for me, my name is Nilo, I’m from Spain, and I studied Anthropology as an undergrad.

## 3

Probably most of you are familiar with Wytham Woods. It’s a semi-natural woodland to the north west of Oxford, where among lots of other projects a population of great and blue tits has been monitored since 1947. 

I am studying the songs of great tits, which is the little bird on top of the hill here. Great tits sing simple songs, but there is a lot of variation from bird to bird. It’s mainly the males that sing, and they do it more often early in the mornings while the female is fertile. The songs are thought to be used both to defend their territories and to attract mates.

I’m going to play a couple of examples, I hope you can hear them ok. 

I guess it’s probably not the word’s most beautiful song, but I’ve come to appreciate it nonetheless.. sometimes anyway

I am interested in these songs for many reasons, but the main one is that the birds have to learn them. They learn them mostly from birds that they encounter before they breed for the first time. 

And this creates very interesting dynamics and opportunities for research.

We can study all sorts of things, like how this gives rise to what we could call song cultural diversity at the population level, how demographic and social factors influence the learning of songs (and the songs themselves), or how the songs change over time.

Many people have studied the songs of great tits before, and this includes some inspiring work done in this same population over the years. So I am definitely not inventing anything new here, of course. Instead, what I am trying to do is to use some new tools to study more birds at once, and, at the same time, have more detailed information for each individual bird.

I’ve spent most of this first year dealing with the logistics of recording and analysing the songs of so many birds, and this is what I’m going to tell you about.

## 4

Now, the nest boxes where the birds breed are checked weekly at the start of the breeding season by hard-working fieldworkers. Whenever a new box was marked as having great tit activity I would go find it—which can be easier said than done—and place a recorder in a tree close to it. 

I used 30 small autonomous recorders, called AudioMoths, which I put inside some waterproof cases I made. You can see one in the picture in the middle here. 

There are always many more birds than recorders, so I moved each recorder to a different nest every three days. This year all the birds were very synchronised in their egg-laying, so things escalated very quickly! 

## 5

OK, so here’s a map of what I recorded this spring. 

Each point is a nest where there were great tits at some point. The bigger the white point, the more songs recorded there. 

Orange points are for nests I didn’t make it to, and blue for those where I didn’t get any songs.

I recorded almost 7 thousand hours of audio, which would take almost a year to listen to if you really wanted to. I ended up with around 180 thousand individual notes in total, which is a big dataset.

## 6

Here you can see a few as an example, this what a single bird sang in a single morning.

Each syllable is represented as a 64 by 64-pixel image, so they all live in a space with effectively 4096 dimensions. Of course, the real number of dimensions along which they vary is much smaller. 

## 7

Here I’ve embedded this space in just two dimensions so that we can visualise it.

At this level, and we’re looking at every note for every bird, there is a lot of continuity, with no distinct clusters. The colours represent how far the male that sung a certain note was from a point in the woods that I picked at random, and you can see that there is a slight local tendency for similar distances to be closer in the embedding.

But I really want to know what happens at the level of each bird, so I took all the songs from each male and again projected them into a lower-dimensional space.

## 8

I can’t show you all of them, but here’s an example. 

The male that sung these notes was born in 2018, one kilometre to the south of where I recorded it. The female was born 800 metres to the north east, also in 2018. They raised 9 chicks, and they all fledged.

We can see that, when we look at individual birds, there are distinct note types. Colours represent clusters that were found by a density-based algorithm.

## 9

Most people have classified great tit songs based on the combination of a few notes that are repeated in what are called phrases, and this may well be the level of organisation that is most important for learning. 

So to infer these in an unsupervised way I’ve computed the transition probabilities between notes and built directed graphs, what you are seeing is an example for the same bird as before. 

## 10

From the adjacency matrix we now have inferred that this bird sings three different song types, and if we plot the temporal sequence, like I’ve done here, that becomes very clear. 

The bar-code plot at the bottom represents the first 100 songs that the bird sung.

## 11

These are just some summary plots for the entire dataset. 

In **A** we can see that the average bird sings around 6 or 8 different notes, which matches other estimates done here and in other populations. Which is a relief!

We can see in **B** that most birds sung a relatively small number of notes, and then there is a long tail.

An then **C** shows that most notes are around a tenth of a second long.

Allright, so what I’ve told you so far has been just the first step in the project. Now I am going to continue collecting data, and will be using it to try to answer a variety of questions about who learns from who, what determines what is learnt, and how songs change over time and space at different levels of description.

I hope you have found it interesting,

I’ll be happy to try to answer any questions that you might have.



–

UMAP = Uniform Manifold Approximation and Projection

PHATE = Potential of Heat-diffusion for Affinity-based Transition Embedding

HDBSCAN





