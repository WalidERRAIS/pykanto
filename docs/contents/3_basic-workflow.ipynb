{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from pykanto.utils.paths import pykanto_data, ProjDirs\n",
    "from pykanto.dataset import SongDataset\n",
    "from pykanto.parameters import Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to load one of the very small sample datasets that are packaged with `pykanto`â€”this will be enough for a first test to familiarise yourself with the package. See [working with paths and directories](../contents/2_paths-and-dirs.md) to learn how to load your own data.\n",
    "\n",
    "This particular dataset consists of a few songs from two male great tits (_Parus major_) in [my study population](http://wythamtits.com/), Wytham Woods, Oxfordshire, UK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Items held:\n",
      "\n",
      "PROJECT: /home/nilomr/projects/pykanto/pykanto\n",
      "DATA: /home/nilomr/projects/pykanto/pykanto/data\n",
      "RAW_DATA: /home/nilomr/projects/pykanto/pykanto/data/segmented/great_tit\n",
      "SEGMENTED: /home/nilomr/projects/pykanto/pykanto/data/segmented/great_tit\n",
      "RESOURCES: /home/nilomr/projects/pykanto/pykanto/resources\n",
      "REPORTS: /home/nilomr/projects/pykanto/pykanto/reports\n",
      "FIGURES: /home/nilomr/projects/pykanto/pykanto/reports/figures\n"
     ]
    }
   ],
   "source": [
    "DATASET_ID = \"GREAT_TIT\"\n",
    "DIRS = pykanto_data(dataset=DATASET_ID)\n",
    "print(DIRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a SongDataset object, which is the main class in `pykanto` and acts as a sort of database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = Parameters() # Using default parameters for simplicity, which you should't!\n",
    "dataset = SongDataset(DATASET_ID, DIRS, parameters=params, overwrite_dataset=True)\n",
    "dataset.vocs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an object `dataset`, which is an instance of the `SongDataset` class and has all of its methods. For example, you might want to segment your songs into discrete notes using `pykanto`'s algorithm, which is a simple amplitude-based method that works reasonably well (based on Tim Sainburg's [vocalseg](https://github.com/timsainb/vocalization-segmentation) and Robert Lachlan's de-echoing method in [Luscinia](https://rflachlan.github.io/Luscinia/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment:\n",
    "dataset.segment_into_units()\n",
    "\n",
    "# Plot an example:\n",
    "for vocalisation in dataset.vocs.index[:1]:\n",
    "    dataset.plot_voc_seg(vocalisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can create spectrogram representations of the units or the average of the units present in the vocalisations of each individual ID in the dataset, project and cluster them, and prepare compressed representations that can be used with the interactive app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_units()\n",
    "dataset.cluster_ids(min_sample=5)\n",
    "dataset.prepare_interactive_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start the interactive app on your browser by simply running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.open_label_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for song_level in [True, False]:\n",
    "#     dataset.parameters.update(song_level=song_level)\n",
    "#     dataset.get_units()\n",
    "\n",
    "# dataset.reload()\n",
    "# for song_level in [True, False]:\n",
    "#     dataset.parameters.update(song_level=song_level)\n",
    "#     dataset.cluster_ids(min_sample=5)\n",
    "\n",
    "# for song_level in [True, False]:\n",
    "#     dataset.parameters.update(song_level=song_level)\n",
    "#     dataset.prepare_interactive_data()\n",
    "\n",
    "# dataset.parameters.update(song_level=True)\n",
    "# dataset.open_label_app()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If need to load an existing dataset:\n",
    "(This needs you to create a ProjDirs object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_dir = DIRS.DATA / \"datasets\" / DATASET_ID / f\"{DATASET_ID}.db\"\n",
    "# dataset = pickle.load(open(out_dir, \"rb\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b97ee16365f5d5f76540b5681d8285b31428be7335efa9f541b550d84bc67ff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('pykanto-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
